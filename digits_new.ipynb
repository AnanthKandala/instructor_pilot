{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import django\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from submissions.digits_classify import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/home/user/Downloads/quiz.pdf\"\n",
    "dpi = 300\n",
    "\n",
    "def pdf_to_images(filepath, dpi, top_percent=0.25, left_percent=0.5, crop_box=None, skip_pages=(0,1,3)):\n",
    "    \"\"\"\n",
    "    Converts a pdf file to a list of images.\n",
    "    If crop_box is not None, then the images are cropped to the specified box.\n",
    "    Otherwise, the images are cropped to the top left corner of the page,\n",
    "    with the width and height specified by top_percent and left_percent.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        The path to the pdf file.\n",
    "    dpi : int\n",
    "        The dpi of the images.\n",
    "    top_percent : float\n",
    "        The percentage of the top of the page to keep.\n",
    "    left_percent : float\n",
    "        The percentage of the left of the page to crop.\n",
    "    crop_box : tuple\n",
    "        A tuple of the form (left, top, right, bottom) that specifies the crop box.\n",
    "    skip_pages : tuple\n",
    "        A tuple of page numbers to skip.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    images : list\n",
    "        A list of images.\n",
    "    \"\"\"\n",
    "    import fitz\n",
    "    from PIL import Image\n",
    "    images = []\n",
    "    doc = fitz.open(filepath)\n",
    "    for page in doc:\n",
    "        if page.number % 4 in skip_pages:\n",
    "            images.append(None)\n",
    "            continue\n",
    "        print(page.number, end=\"\\r\")\n",
    "        rect = page.rect  # the page rectangle\n",
    "        rect.y1 = rect.y0 + (rect.y1 - rect.y0) * top_percent\n",
    "        rect.x1 = rect.x0 + (rect.x1 - rect.x0) * left_percent\n",
    "\n",
    "        pix = page.get_pixmap(dpi=dpi, clip=rect)\n",
    "        images.append(Image.frombytes(mode=\"RGB\", size=[pix.width, pix.height], data=pix.samples))\n",
    "    \n",
    "    return images\n",
    "\n",
    "quiz_imgs = pdf_to_images(filepath, dpi, top_percent=0.25, left_percent=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_imgs.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pages_per_submission = 4  \n",
    "if len(quiz_imgs) % num_pages_per_submission != 0:\n",
    "    raise ValueError(\n",
    "        f\"The number of pages in the pdf is not a multiple of {num_pages_per_submission}\")\n",
    "\n",
    "# convert imgs to nested list every `num_pages_per_quiz`\n",
    "# for example, if num_pages_per_quiz=2, then:\n",
    "# [ [img1, img2], [img3, img4], ... ]\n",
    "quizzes_img_list = [list(a) for a in zip(*[iter(quiz_imgs)] * num_pages_per_submission)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating a copy of the image list\")\n",
    "img_list = copy.deepcopy(quizzes_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(img_list[2][2].size)\n",
    "plt.imshow(img_list[2][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_idx in range(len(img_list)):\n",
    "    img = np.array(img_list[sub_idx][2])\n",
    "    # copy the image\n",
    "    img_copy = copy.deepcopy(img)\n",
    "    # convert the image to grayscale\n",
    "    img_gray = cv2.cvtColor(img_copy, cv2.COLOR_RGB2GRAY)\n",
    "    # apply a threshold to the image\n",
    "    ret, thresh = cv2.threshold(img_gray, 127, 255, 0)\n",
    "    # find the contours in the image\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # sort the contours by area\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    count = 0\n",
    "    for i in range(100):\n",
    "        if cv2.contourArea(contours[i]) < 100000 and cv2.contourArea(contours[i]) > 10000:\n",
    "            count += 1\n",
    "            # approximate the contour with a rectangle\n",
    "            rect = cv2.minAreaRect(contours[i])\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int0(box)\n",
    "            # or more concisely\n",
    "            min_x, min_y = np.min(box, axis=0)\n",
    "            max_x, max_y = np.max(box, axis=0)\n",
    "            # pad 10 pixels on each side and crop the image\n",
    "            img_crop = img[min_y-3:max_y+3, min_x-3:max_x+3]\n",
    "\n",
    "            # plt.imshow(img_crop)\n",
    "            # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template_path = '/home/ionmich/repos/instructor_pilot/media/template.png'\n",
    "# template_150 = cv2.imread(template_path, cv2.IMREAD_UNCHANGED)\n",
    "# template = apply_scale_rotate(template_150, dpi//150, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(template, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_lines_img(\n",
    "    img, \n",
    "    mode, \n",
    "    rect_kernel_size=30, \n",
    "    rect_kernel_width=1, \n",
    "    restruct_kernel_size=1, \n",
    "    do_reconstruct=False,\n",
    "    dpi=150):\n",
    "\n",
    "    if mode == \"vertical\":\n",
    "        rect_kernel = (rect_kernel_width,rect_kernel_size)\n",
    "        restruct_kernel = (restruct_kernel_size,rect_kernel_width)\n",
    "    elif mode == \"horizontal\":\n",
    "        rect_kernel = (rect_kernel_size,rect_kernel_width)\n",
    "        restruct_kernel = (rect_kernel_width,restruct_kernel_size)\n",
    "    else:\n",
    "        raise ValueError(\"mode must be either 'vertical' or 'horizontal'\")\n",
    "    removed = img.copy()\n",
    "    \n",
    "    thresh = cv2.threshold(removed, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    if mode == \"vertical\":\n",
    "        plt.imshow(removed, cmap=\"gray\")\n",
    "        plt.show()\n",
    "        plt.imshow(thresh, cmap=\"gray\")\n",
    "        plt.show()\n",
    "    # Remove vertical\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, rect_kernel)\n",
    "    detected_lines = cv2.morphologyEx(\n",
    "        thresh, \n",
    "        cv2.MORPH_OPEN, \n",
    "        vertical_kernel, \n",
    "        iterations=1)\n",
    "    cnts = cv2.findContours(\n",
    "        detected_lines, \n",
    "        cv2.RETR_EXTERNAL, \n",
    "        cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    print(f\"Found {len(cnts)} lines in {mode} mode.\")\n",
    "    print(f\"Checking if they are in the right location...\")\n",
    "\n",
    "    if cnts:\n",
    "        if mode == \"vertical\":\n",
    "            x_left = min(c.mean(axis=0)[0,0] for c in cnts)\n",
    "            x_right = max(c.mean(axis=0)[0,0] for c in cnts)\n",
    "            avg_x_distance = (x_right - x_left) / UFID_LENGTH\n",
    "            low, high = x_left, x_right\n",
    "        elif mode == \"horizontal\":\n",
    "            x_top = min(c.mean(axis=0)[0,1] for c in cnts)\n",
    "            x_bottom = max(c.mean(axis=0)[0,1] for c in cnts)\n",
    "            low, high = x_top, x_bottom\n",
    "    else:\n",
    "        return img, (None, None)\n",
    "\n",
    "    count_lines = 0\n",
    "    for c in cnts:\n",
    "        if mode==\"vertical\":\n",
    "            x_loc = c.mean(axis=0)[0,0]\n",
    "            # if x_loc is approximately multiple of avg_x_distance, then it's a valid line\n",
    "            if (abs((x_loc - x_left) % avg_x_distance)>2*(dpi//150)\n",
    "            and abs((x_loc - x_left) % avg_x_distance - avg_x_distance)>2*(dpi//150)\n",
    "            ):\n",
    "                print(\"Found vertical line, but won't remove because it's not a multiple of avg_x_distance away from x_left\")\n",
    "                continue\n",
    "        count_lines += 1\n",
    "        cv2.drawContours(removed, [c], -1, (255,255,255), 2*dpi//150)\n",
    "    \n",
    "    print(f\"Overall, {count_lines} lines were removed in {mode} mode.\")\n",
    "\n",
    "    plt.imshow(removed, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    # Repair image\n",
    "    if do_reconstruct:\n",
    "        repair_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "        removed = 255 - removed\n",
    "        dilate = cv2.dilate(removed, repair_kernel, iterations=3)\n",
    "        pre_result = cv2.bitwise_and(dilate, thresh)\n",
    "\n",
    "        result = cv2.morphologyEx(pre_result, cv2.MORPH_CLOSE, repair_kernel, iterations=3)\n",
    "        final = cv2.bitwise_and(result, thresh)\n",
    "        invert_final = 255 - final\n",
    "    else:\n",
    "        invert_final = removed\n",
    "\n",
    "    return invert_final , (low, high)\n",
    "\n",
    "def apply_scale_rotate(img, scale, angle):\n",
    "    \"\"\"Apply scale and rotation to image\"\"\"\n",
    "    width = int(img.shape[1] * scale)\n",
    "    height = int(img.shape[0] * scale)\n",
    "    dim = (width, height)\n",
    "    scaled_img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    M = cv2.getRotationMatrix2D((width/2, height/2), angle, 1)\n",
    "    rotated_img = cv2.warpAffine(scaled_img, M, (width, height))\n",
    "    return rotated_img\n",
    "\n",
    "def find_best_scale_and_angle(template, img_list, n_iter=100, skip_pages=[0,1,3], match_method=None):\n",
    "    \"\"\"Do a Monte Carlo search for the best scale and angle to align the template to the image\"\"\"\n",
    "    import random\n",
    "    # temperature\n",
    "    T = 1\n",
    "    if match_method is None:\n",
    "        match_method = cv2.TM_SQDIFF_NORMED\n",
    "    if match_method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "        best_score = np.inf\n",
    "    else:\n",
    "        best_score = 0\n",
    "    best_scale = 1.0\n",
    "    best_angle = 0\n",
    "    # step size for Marcov chain\n",
    "    scale_sigma = 0.01\n",
    "    angle_sigma = 0.01\n",
    "    # start with scale and angle of 1.0 and 0\n",
    "    scale = best_scale\n",
    "    angle = best_angle\n",
    "    score = best_score\n",
    "    # prior for scale and angle is gaussian with mean 1.0 and 0\n",
    "    # and variances 0.1 and 1.0\n",
    "    scale_prior = lambda x: np.exp(-0.5*(x-1.0)**2/0.1**2)\n",
    "    angle_prior = lambda x: np.exp(-0.5*x**2/1.0**2)\n",
    "    prior = lambda x,y: scale_prior(x)*angle_prior(y)\n",
    "    for i in range(n_iter):\n",
    "        # scale and angle search\n",
    "        proposed_scale = scale + random.gauss(0, scale_sigma)\n",
    "        propose_angle =  angle + random.gauss(0, angle_sigma)\n",
    "        print(\"proposed: scale\", proposed_scale, \"angle\", propose_angle, end=\"\\r\")\n",
    "        # scale the template\n",
    "        template_ = apply_scale_rotate(template, proposed_scale, propose_angle)\n",
    "        template_rgb, template_luminance = template_[:,:,:3], template_[:,:,3]\n",
    "        \n",
    "        # randomly choose an image to match to\n",
    "        sub_idx = random.randint(0, len(img_list)-1)\n",
    "        # select page_idx randomly from 0 to 3 except for skip_pages\n",
    "        page_idx = random.choice([i for i in range(4) if i not in skip_pages])\n",
    "        img_rgb = np.array(img_list[sub_idx][page_idx])\n",
    "        # image_to_match = cv2.erode(img_rgb, None, iterations=1)\n",
    "        # template_rgb_ = cv2.erode(template_rgb, None, iterations=1)\n",
    "        # copy\n",
    "        image_to_match = img_rgb.copy()\n",
    "        template_rgb_ = template_rgb.copy()\n",
    "        result = cv2.matchTemplate(image_to_match, template_rgb_, match_method)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "        if match_method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "            # implement the Metropolis-Hastings acceptance criterion\n",
    "            # accept if the new score is better than the old score\n",
    "            # or if the new score is worse than the old score, accept with probability exp(-(new-old)/T)\n",
    "            prior_ratio = prior(proposed_scale, propose_angle) / prior(scale, angle)\n",
    "            if min_val < best_score or random.random() < prior_ratio * np.exp(-(min_val-best_score)/T):\n",
    "                angle = propose_angle\n",
    "                scale = proposed_scale\n",
    "            if min_val < best_score:\n",
    "                best_score = min_val\n",
    "                best_scale = proposed_scale\n",
    "                best_angle = propose_angle\n",
    "        else:\n",
    "            if max_val > best_score or random.random() < prior_ratio * np.exp((max_val - best_score)/T):\n",
    "                angle = propose_angle\n",
    "                scale = proposed_scale\n",
    "            if max_val > best_score:\n",
    "                best_score = max_val\n",
    "                best_scale = proposed_scale\n",
    "                best_angle = propose_angle\n",
    "        # print and overwrite in the same line to show progress\n",
    "    print(\"best: scale\", best_scale, \"angle\", best_angle, \"score\", best_score)\n",
    "    best_template = apply_scale_rotate(template, best_scale, best_angle)\n",
    "    return best_template, best_scale, best_angle\n",
    "\n",
    "def get_possible_boundaries(padding_px):\n",
    "    sub_boundaries = {}\n",
    "    for sub_idx in range(len(img_list)):\n",
    "        sub_boundaries[sub_idx] = []\n",
    "        img = np.array(img_list[sub_idx][2])\n",
    "        # copy the image\n",
    "        img_copy = img\n",
    "        # convert the image to grayscale\n",
    "        img_gray = cv2.cvtColor(img_copy, cv2.COLOR_RGB2GRAY)\n",
    "        # apply a threshold to the image\n",
    "        ret, thresh = cv2.threshold(img_gray, 127, 255, 0)\n",
    "        # find the contours in the image\n",
    "        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # sort the contours by area\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "        count = 0\n",
    "        for i in range(100):\n",
    "            if cv2.contourArea(contours[i]) < 100000 and cv2.contourArea(contours[i]) > 10000:\n",
    "                count += 1\n",
    "                # approximate the contour with a rectangle\n",
    "                rect = cv2.minAreaRect(contours[i])\n",
    "                box = cv2.boxPoints(rect)\n",
    "                box = np.int0(box)\n",
    "                # or more concisely\n",
    "                min_x, min_y = np.min(box, axis=0)\n",
    "                max_x, max_y = np.max(box, axis=0)\n",
    "                # pad \n",
    "                sub_boundaries[sub_idx].append((\n",
    "                    max(0, min_x-padding_px),\n",
    "                    max(0, min_y-padding_px),\n",
    "                    min(img.shape[1], max_x+padding_px),\n",
    "                    min(img.shape[0], max_y+padding_px)\n",
    "                ))\n",
    "        \n",
    "    return sub_boundaries\n",
    "\n",
    "def new_main(img_list):\n",
    "    # get possible boundaries\n",
    "    padding_px = round(3 * dpi / 150)\n",
    "    sub_boundaries = get_possible_boundaries(padding_px)\n",
    "    \n",
    "    for sub_idx in range(len(img_list)):\n",
    "        for page_idx in range(len(img_list[sub_idx])):\n",
    "            if page_idx != 2:\n",
    "                continue\n",
    "            # now we have the boundaries so we can crop the image\n",
    "            # withouth the need of the template!\n",
    "            img_rgb = np.array(img_list[sub_idx][page_idx])\n",
    "            img = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "            # try each possible boundary\n",
    "            for boundary in sub_boundaries[sub_idx]:\n",
    "                try:\n",
    "                    img_ = img[boundary[1]:boundary[3], boundary[0]:boundary[2]]\n",
    "                    plt.imshow(img_, cmap=\"gray\")\n",
    "                    plt.show()\n",
    "\n",
    "                    img_no_v, (x_left, x_right) = remove_lines_img(\n",
    "                        img_, \n",
    "                        mode=\"vertical\", \n",
    "                        rect_kernel_size=30*dpi//150, \n",
    "                        rect_kernel_width=1, \n",
    "                        do_reconstruct=False\n",
    "                        )\n",
    "\n",
    "                    img_no_h, _ = remove_lines_img(\n",
    "                        img_, \n",
    "                        mode=\"horizontal\", \n",
    "                        rect_kernel_size=70*dpi//150, \n",
    "                        rect_kernel_width=1, \n",
    "                        do_reconstruct=False\n",
    "                        )\n",
    "                    img_nolines = cv2.bitwise_or(img_no_v, img_no_h)\n",
    "                    plt.imshow(img_nolines, cmap=\"gray\")\n",
    "                    plt.show()\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    plt.imshow(img_, cmap=\"gray\")\n",
    "                    plt.show()\n",
    "                    continue\n",
    "new_main(img_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_imgs = get_all_digits_new(\n",
    "    img_list,\n",
    "    dpi=300,\n",
    "    pages_to_skip=(0,1,3),\n",
    ")\n",
    "# note that the digit_imgs is a dict with (idx_submission, idx_page) as key \n",
    "# and an image (np.array) as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(img_list)):\n",
    "    # get the images of digits in page 3\n",
    "    imgs = digit_imgs[(i, 2)]\n",
    "    \n",
    "    # show the output images in cmap gray, with 8 images per row\n",
    "    fig, ax = plt.subplots(1, len(imgs), figsize=(20, 20))\n",
    "    for j in range(len(imgs)):\n",
    "        ax[j].imshow(imgs[j], cmap=\"gray\")\n",
    "        ax[j].axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = cv2.imread(\"media/template.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# pad 100 pixels to the template\n",
    "template = np.pad(template, 100, mode=\"constant\", constant_values=255)\n",
    "# rotate the template by 20 degrees\n",
    "template = apply_scale_rotate(template, 10, 20)\n",
    "\n",
    "# plot\n",
    "plt.imshow(template, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the hough transform\n",
    "# and plot the result\n",
    "src = template\n",
    "\n",
    "dst = cv2.Canny(src, 50, 200, None, 3)\n",
    "\n",
    "# Copy edges to the images that will display the results in BGR\n",
    "cdst = cv2.cvtColor(dst, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "\n",
    "linesP = cv2.HoughLinesP(dst, 1, np.pi / 180, 10, None, 20, 10)\n",
    "\n",
    "if linesP is not None:\n",
    "    for i in range(0, len(linesP)):\n",
    "        l = linesP[i][0]\n",
    "        cv2.line(cdst, (l[0], l[1]), (l[2], l[3]), (0,0,255), 3, cv2.LINE_AA)\n",
    "\n",
    "# or with plt\n",
    "plt.imshow(src, cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.imshow(cdst, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('django-tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9bd70bfd4d5663c1ff860d0b56fe817ee15536fb7b0cc7b3062f2b0f4009c46c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
