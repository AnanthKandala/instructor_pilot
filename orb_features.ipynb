{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using opencv2 to cluster images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import OPTICS, cluster_optics_dbscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change `X` and `Y` in the glob path to the location of your images to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = glob.glob('media/submissions/course_X/assignment_Y/img/*-page-3-*.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw matches between two images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if len(image_paths) < 2:\n",
    "    raise ValueError('Not enough images in this folder. Fix the path to the images.')\n",
    "random_image_paths = np.random.choice(image_paths, 2, replace=False)\n",
    "img1 = cv2.imread(random_image_paths[0])\n",
    "img2 = cv2.imread(random_image_paths[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do image alignment with ORB\n",
    "orb = cv2.ORB_create()\n",
    "kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "matches = bf.match(des1, des2)\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "# draw the matches\n",
    "img_f = cv2.drawMatches(img1, kp1, img2, kp2, matches[:100], None, flags=2)\n",
    "\n",
    "\n",
    "plt.imshow(img_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure similarity from an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MAX_FEATURES` and `GOOD_MATCH_PERCENT` appear to be the main parameters to tune for clustering.\n",
    "With `MAX_FEATURES = 5000`, `GOOD_MATCH_PERCENT = 0.15`, clusering works amazingly well\n",
    "but it takes a long time to run. With these set to `2000` and `0.15`,\n",
    "it runs much faster, and the clustering is still pretty good.\n",
    "The other important parameters to tune are:\n",
    "- the OPTICS `min_samples` and \n",
    "- the function to calculate the distance between two images. Currently, it's just the weighed number of aligned good matches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 2000\n",
    "GOOD_MATCH_PERCENT = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def ORB_features(img: np.ndarray, ORB_obj: cv2.ORB) -> Tuple[List[cv2.KeyPoint], np.ndarray]:\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    keypoints, descriptors = ORB_obj.detectAndCompute(img, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "def get_all_features(imgs: dict) -> tuple:\n",
    "    \n",
    "    all_keypoints: List[List[cv2.KeyPoint]] = []\n",
    "    all_descriptors: List[np.ndarray] = []\n",
    "    for path, img in imgs.items():\n",
    "        orb: cv2.ORB = cv2.ORB_create(MAX_FEATURES)\n",
    "        keypoints: List[cv2.KeyPoint]\n",
    "        descriptors: np.ndarray\n",
    "        keypoints, descriptors = ORB_features(img, orb)\n",
    "        all_keypoints.append(keypoints)\n",
    "        all_descriptors.append(descriptors)\n",
    "\n",
    "    return all_keypoints, all_descriptors\n",
    "    \n",
    "def compare_images(keypoints1: List[cv2.KeyPoint], keypoints2: List[cv2.KeyPoint],\n",
    "                   descriptors1: np.ndarray, descriptors2: np.ndarray) -> Tuple[np.ndarray, float]:\n",
    "  # Match features.\n",
    "  matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "  matches = matcher.match(descriptors1, descriptors2, None)\n",
    "\n",
    "  # Sort matches by score\n",
    "  matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "  # Remove not so good matches\n",
    "  numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "  matches = matches[:numGoodMatches]\n",
    "\n",
    "  # Extract location of good matches\n",
    "  points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "  points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "  for i, match in enumerate(matches):\n",
    "    points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "    points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "  # Find affine transform\n",
    "  h, mask = cv2.estimateAffinePartial2D(points1, points2)\n",
    "  # calculate the weighted sum of the inliers,\n",
    "  # where the weights are the distances between the hamming distances\n",
    "  inv_distances = np.array([1/match.distance if match.distance > 0 else 1 for match in matches])\n",
    "  weighted_sum = np.sum(mask * inv_distances)\n",
    "\n",
    "  return h, weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index_of_image = np.random.randint(0, len(image_paths))\n",
    "\n",
    "path1 = image_paths[random_index_of_image]\n",
    "img1 = cv2.imread(path1)\n",
    "cv2_images = { path: cv2.imread(path) for path in image_paths }\n",
    "\n",
    "diffs = {}\n",
    "print(\"starting comparison\")\n",
    "for path in image_paths:\n",
    "  if os.path.basename(path) != os.path.basename(path1):\n",
    "    img2 = cv2_images[path]\n",
    "    orb = cv2.ORB_create(MAX_FEATURES)\n",
    "    keypoints1, descriptors1 = ORB_features(img1, orb)\n",
    "    orb = cv2.ORB_create(MAX_FEATURES)\n",
    "    keypoints2, descriptors2 = ORB_features(img2, orb)\n",
    "    h, metric = compare_images(keypoints1, keypoints2, descriptors1, descriptors2)\n",
    "    \n",
    "\n",
    "    batch_id = os.path.basename(path).split('-')[3]\n",
    "    submission_id = os.path.basename(path).split('-')[1]\n",
    "    print(\"Estimated metric with batch {} and submission {} : \\n\".format(batch_id, submission_id), metric)\n",
    "    diffs[path] = {\n",
    "      'batch_id': batch_id, \n",
    "      'submission_id': submission_id, \n",
    "      'metric': metric}\n",
    "\n",
    "df = pd.DataFrame.from_dict(diffs, orient='index')\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns={'index': 'path'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the histogram of the silimarity metrics\n",
    "# color the bars based on the batch id\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize':(8,6)})\n",
    "sns.histplot(data=df, x=\"metric\", hue=\"batch_id\", multiple=\"stack\", bins=100)\n",
    "# make the x-axis logarithmic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster images based on their features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_metric(x, y, keypoint_vectors, descriptor_vectors):\n",
    "    i, j = int(x[0]), int(y[0])     # extract indices\n",
    "    return 1 / compare_images(\n",
    "        keypoint_vectors[i], keypoint_vectors[j],\n",
    "        descriptor_vectors[i], descriptor_vectors[j]\n",
    "    )[1]\n",
    "\n",
    "cv2_images = { path: cv2.imread(path) for path in image_paths }\n",
    "# first calculate all the feature vectors\n",
    "print(\"calculating feature vectors\")\n",
    "keypoint_vectors, descriptor_vectors = get_all_features(cv2_images)\n",
    "\n",
    "print(\"calculating distance matrix\")\n",
    "# create a distance matrix\n",
    "dist_matrix = np.zeros((len(image_paths), len(image_paths)))\n",
    "for i in range(len(image_paths)):\n",
    "    print(\"comparing {} and 0\\t\\t\".format(i), end='\\r')\n",
    "    for j in range(i+1, len(image_paths)):\n",
    "        print(\"comparing {} and {}\".format(i, j), end='\\r')\n",
    "        dist_matrix[i, j] = distance_metric([i], [j], keypoint_vectors, descriptor_vectors)\n",
    "        dist_matrix[j, i] = dist_matrix[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize':(8,6)})\n",
    "df = pd.DataFrame(dist_matrix)\n",
    "# add the batch id to the dataframe\n",
    "df['batch_id'] = [os.path.basename(path).split('-')[3] for path in image_paths]\n",
    "# add the path to the dataframe\n",
    "idx = np.random.randint(0, len(image_paths))\n",
    "df['path'] = image_paths\n",
    "sns.histplot(\n",
    "    data=df, \n",
    "    x=idx, \n",
    "    hue=\"batch_id\", \n",
    "    multiple=\"stack\",\n",
    "    bins=100)\n",
    "\n",
    "# title the plot\n",
    "plt.title(f\"Histogram of distances from {os.path.basename(image_paths[idx])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"clustering images\")\n",
    "# cluster the images\n",
    "clustering = OPTICS(\n",
    "    metric=\"precomputed\",\n",
    "    min_samples=10, \n",
    "    metric_params={\n",
    "        'keypoint_vectors': keypoint_vectors, \n",
    "        'descriptor_vectors': descriptor_vectors},\n",
    ").fit(dist_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_200 = cluster_optics_dbscan(\n",
    "    reachability=clustering.reachability_,\n",
    "    core_distances=clustering.core_distances_,\n",
    "    ordering=clustering.ordering_,\n",
    "    eps=1)\n",
    "\n",
    "space = np.arange(len(dist_matrix))\n",
    "reachability = clustering.reachability_[clustering.ordering_]\n",
    "labels = clustering.labels_[clustering.ordering_]\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.title('Automatic Clustering')\n",
    "\n",
    "\n",
    "# Reachability plot\n",
    "colors = [\"g.\", \"r.\", \"b.\", \"y.\", \"c.\"]\n",
    "for klass, color in zip(range(0, 5), colors):\n",
    "    Xk = space[labels == klass]\n",
    "    Rk = reachability[labels == klass]\n",
    "    ax1.plot(Xk, Rk, color, alpha=0.3)\n",
    "ax1.plot(space[labels == -1], reachability[labels == -1], \"k.\", alpha=0.3)\n",
    "ax1.plot(space, np.full_like(space, 0, dtype=float), \"k\", alpha=0.5)\n",
    "ax1.set_ylabel(\"Reachability (epsilon distance)\")\n",
    "ax1.set_title(\"Reachability Plot\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('django-tess')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1228fc6ae4660366758bb0198d09d50a0df92d002155cbb6fa415bb38d73d90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
